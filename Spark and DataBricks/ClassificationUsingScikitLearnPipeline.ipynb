{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a239893-a4c3-4d48-b52a-d05ac38f9183",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Dataset Link-https://www.kaggle.com/arashnic/hr-ana?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcf12dfa-57a1-4860-a18d-2e721dd1ff35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting bamboolib\n  Downloading bamboolib-1.30.19-py3-none-any.whl (2.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.8/2.8 MB 20.8 MB/s eta 0:00:00\nRequirement already satisfied: pandas<2.0.0,>=1.1.0 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (1.4.4)\nRequirement already satisfied: ipywidgets<8.0.0,>=7.6.0 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (7.7.2)\nCollecting ppscore<2.0.0,>=1.2.0\n  Downloading ppscore-1.3.0.tar.gz (17 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: cryptography>=2.6.1 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (37.0.1)\nCollecting xlrd>=1.0.0\n  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.5/96.5 kB 11.4 MB/s eta 0:00:00\nRequirement already satisfied: plotly<6.0.0,>=4.9.0 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (5.9.0)\nCollecting toml>=0.10.0\n  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: packaging>=19.2 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (21.3)\nRequirement already satisfied: psutil<6,>=5.4.2 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (5.9.0)\nRequirement already satisfied: statsmodels<1.0.0 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (0.13.2)\nCollecting ipyslickgrid==0.0.3\n  Downloading ipyslickgrid-0.0.3.tar.gz (51.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.4/51.4 MB 20.2 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: attrs>=20.3.0 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (21.4.0)\nRequirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (1.1.1)\nRequirement already satisfied: pygments in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (2.11.2)\nRequirement already satisfied: jedi<1.0.0 in /databricks/python3/lib/python3.10/site-packages (from bamboolib) (0.18.1)\nRequirement already satisfied: notebook>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from ipyslickgrid==0.0.3->bamboolib) (6.4.12)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.10/site-packages (from cryptography>=2.6.1->bamboolib) (1.15.1)\nRequirement already satisfied: traitlets>=4.3.1 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (5.1.1)\nRequirement already satisfied: ipykernel>=4.5.1 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (6.17.1)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (3.6.1)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.0)\nRequirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (1.0.0)\nRequirement already satisfied: ipython>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (8.10.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /databricks/python3/lib/python3.10/site-packages (from jedi<1.0.0->bamboolib) (0.8.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>=19.2->bamboolib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas<2.0.0,>=1.1.0->bamboolib) (2.8.2)\nRequirement already satisfied: numpy>=1.21.0 in /databricks/python3/lib/python3.10/site-packages (from pandas<2.0.0,>=1.1.0->bamboolib) (1.21.5)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas<2.0.0,>=1.1.0->bamboolib) (2022.1)\nRequirement already satisfied: tenacity>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from plotly<6.0.0,>=4.9.0->bamboolib) (8.1.0)\nRequirement already satisfied: scipy>=1.3.2 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=0.20.2->bamboolib) (1.9.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=0.20.2->bamboolib) (2.2.0)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=0.20.2->bamboolib) (1.2.0)\nRequirement already satisfied: patsy>=0.5.2 in /databricks/python3/lib/python3.10/site-packages (from statsmodels<1.0.0->bamboolib) (0.5.2)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.1->bamboolib) (2.21)\nRequirement already satisfied: nest-asyncio in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.6.0->bamboolib) (1.5.5)\nRequirement already satisfied: matplotlib-inline>=0.1 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.1.6)\nRequirement already satisfied: debugpy>=1.0 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.6.0->bamboolib) (1.6.0)\nRequirement already satisfied: tornado>=6.1 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.6.0->bamboolib) (6.1)\nRequirement already satisfied: pyzmq>=17 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.6.0->bamboolib) (23.2.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /databricks/python3/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.6.0->bamboolib) (7.3.4)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /databricks/python3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (3.0.36)\nRequirement already satisfied: decorator in /databricks/python3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (5.1.1)\nRequirement already satisfied: pickleshare in /databricks/python3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.7.5)\nRequirement already satisfied: pexpect>4.3 in /databricks/python3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (4.8.0)\nRequirement already satisfied: backcall in /databricks/python3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.0)\nRequirement already satisfied: stack-data in /databricks/python3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.6.2)\nRequirement already satisfied: terminado>=0.8.3 in /databricks/python3/lib/python3.10/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.13.1)\nRequirement already satisfied: prometheus-client in /databricks/python3/lib/python3.10/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.14.1)\nRequirement already satisfied: argon2-cffi in /databricks/python3/lib/python3.10/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (21.3.0)\nRequirement already satisfied: nbformat in /databricks/python3/lib/python3.10/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (5.5.0)\nRequirement already satisfied: nbconvert>=5 in /databricks/python3/lib/python3.10/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (6.4.4)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.11.3)\nRequirement already satisfied: jupyter-core>=4.6.1 in /databricks/python3/lib/python3.10/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.11.2)\nRequirement already satisfied: Send2Trash>=1.8.0 in /databricks/python3/lib/python3.10/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.8.0)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels<1.0.0->bamboolib) (1.16.0)\nRequirement already satisfied: entrypoints in /databricks/python3/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.4)\nRequirement already satisfied: bleach in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.1.0)\nRequirement already satisfied: defusedxml in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.7.1)\nRequirement already satisfied: testpath in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.6.0)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.11.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.8.4)\nRequirement already satisfied: pandocfilters>=1.4.1 in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.5.0)\nRequirement already satisfied: jupyterlab-pygments in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.1.2)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /databricks/python3/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.5.13)\nRequirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.10/site-packages (from jinja2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.0.1)\nRequirement already satisfied: jsonschema>=2.6 in /databricks/python3/lib/python3.10/site-packages (from nbformat->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.16.0)\nRequirement already satisfied: fastjsonschema in /databricks/python3/lib/python3.10/site-packages (from nbformat->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.18.0)\nRequirement already satisfied: ptyprocess>=0.5 in /databricks/python3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.7.0)\nRequirement already satisfied: wcwidth in /databricks/python3/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.5)\nRequirement already satisfied: argon2-cffi-bindings in /databricks/python3/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (21.2.0)\nRequirement already satisfied: pure-eval in /databricks/python3/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.2)\nRequirement already satisfied: executing>=1.2.0 in /databricks/python3/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /databricks/python3/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (2.2.1)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /databricks/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.18.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.3.1)\nRequirement already satisfied: webencodings in /databricks/python3/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.5.1)\nBuilding wheels for collected packages: ipyslickgrid, ppscore\n  Building wheel for ipyslickgrid (setup.py): started\n  Building wheel for ipyslickgrid (setup.py): finished with status 'done'\n  Created wheel for ipyslickgrid: filename=ipyslickgrid-0.0.3-py2.py3-none-any.whl size=1823269 sha256=3387db6ca822facabe7418f0d053af46ceaa23470c561e0cbb9a1760d3e848d5\n  Stored in directory: /root/.cache/pip/wheels/4d/d5/90/4073d755274eb9c595c5aeb32d58164e57190199618e546dca\n  Building wheel for ppscore (setup.py): started\n  Building wheel for ppscore (setup.py): finished with status 'done'\n  Created wheel for ppscore: filename=ppscore-1.3.0-py2.py3-none-any.whl size=13167 sha256=4f3663fc257b13c738e9f95d995e9da10f457b7e3dfaec3e41354d9cafafda40\n  Stored in directory: /root/.cache/pip/wheels/42/87/10/00056aa2d2624f1b9374db6a0d5245da9a3d87bdc9247c1a56\nSuccessfully built ipyslickgrid ppscore\nInstalling collected packages: xlrd, toml, ppscore, ipyslickgrid, bamboolib\nSuccessfully installed bamboolib-1.30.19 ipyslickgrid-0.0.3 ppscore-1.3.0 toml-0.10.2 xlrd-2.0.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install bamboolib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "396893fc-67f6-4bb5-8b90-22ac0619c783",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting mlflow\n  Using cached mlflow-2.7.1-py3-none-any.whl (18.5 MB)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.1.1)\nRequirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/lib/python3/dist-packages (from mlflow) (4.6.4)\nRequirement already satisfied: packaging<24 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (21.3)\nCollecting querystring-parser<2\n  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (2.28.1)\nCollecting gitpython<4,>=2.1.0\n  Using cached GitPython-3.1.37-py3-none-any.whl (190 kB)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.4)\nCollecting sqlparse<1,>=0.4.0\n  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\nCollecting pyyaml<7,>=5.1\n  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\nCollecting sqlalchemy<3,>=1.4.0\n  Using cached SQLAlchemy-2.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\nCollecting docker<7,>=4.0.0\n  Using cached docker-6.1.3-py3-none-any.whl (148 kB)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.9.1)\nRequirement already satisfied: pytz<2024 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (2022.1)\nRequirement already satisfied: pyarrow<14,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.0)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.4.4)\nCollecting gunicorn<22\n  Using cached gunicorn-21.2.0-py3-none-any.whl (80 kB)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (0.4)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.21.5)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (2.11.3)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.5.2)\nCollecting Flask<3\n  Using cached flask-2.3.3-py3-none-any.whl (96 kB)\nCollecting markdown<4,>=3.3\n  Using cached Markdown-3.5-py3-none-any.whl (101 kB)\nCollecting alembic!=1.10.0,<2\n  Using cached alembic-1.12.0-py3-none-any.whl (226 kB)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.19.4)\nCollecting cloudpickle<3\n  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\nCollecting databricks-cli<1,>=0.8.7\n  Using cached databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\nCollecting Mako\n  Using cached Mako-1.2.4-py3-none-any.whl (78 kB)\nRequirement already satisfied: typing-extensions>=4 in /databricks/python3/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.3.0)\nRequirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\nRequirement already satisfied: oauthlib>=3.1.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.0)\nRequirement already satisfied: urllib3<3,>=1.26.7 in /databricks/python3/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.11)\nCollecting tabulate>=0.7.7\n  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\nRequirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\nCollecting websocket-client>=0.32.0\n  Using cached websocket_client-1.6.4-py3-none-any.whl (57 kB)\nCollecting blinker>=1.6.2\n  Using cached blinker-1.6.3-py3-none-any.whl (13 kB)\nCollecting itsdangerous>=2.1.2\n  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\nCollecting Jinja2<4,>=2.11\n  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\nCollecting Werkzeug>=2.3.7\n  Using cached werkzeug-3.0.0-py3-none-any.whl (226 kB)\nCollecting click<9,>=7.0\n  Using cached click-8.1.7-py3-none-any.whl (97 kB)\nCollecting gitdb<5,>=4.0.1\n  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.0.1)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.2.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.25.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2022.9.14)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (2.2.0)\nCollecting greenlet!=0.4.17\n  Using cached greenlet-3.0.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (612 kB)\nCollecting smmap<6,>=3.0.1\n  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\nCollecting MarkupSafe>=2.0\n  Using cached MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nInstalling collected packages: websocket-client, tabulate, sqlparse, smmap, querystring-parser, pyyaml, MarkupSafe, markdown, itsdangerous, greenlet, cloudpickle, click, blinker, Werkzeug, sqlalchemy, Mako, Jinja2, gunicorn, gitdb, docker, databricks-cli, gitpython, Flask, alembic, mlflow\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-8795942e-086a-4b41-8d8a-c91f4ceb2dfb\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n  Attempting uninstall: click\n    Found existing installation: click 8.0.4\n    Not uninstalling click at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-8795942e-086a-4b41-8d8a-c91f4ceb2dfb\n    Can't uninstall 'click'. No files were found to uninstall.\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.4\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-8795942e-086a-4b41-8d8a-c91f4ceb2dfb\n    Can't uninstall 'blinker'. No files were found to uninstall.\n  Attempting uninstall: Jinja2\n    Found existing installation: Jinja2 2.11.3\n    Not uninstalling jinja2 at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-8795942e-086a-4b41-8d8a-c91f4ceb2dfb\n    Can't uninstall 'Jinja2'. No files were found to uninstall.\nSuccessfully installed Flask-2.3.3 Jinja2-3.1.2 Mako-1.2.4 MarkupSafe-2.1.3 Werkzeug-3.0.0 alembic-1.12.0 blinker-1.6.3 click-8.1.7 cloudpickle-2.2.1 databricks-cli-0.18.0 docker-6.1.3 gitdb-4.0.10 gitpython-3.1.37 greenlet-3.0.0 gunicorn-21.2.0 itsdangerous-2.1.2 markdown-3.5 mlflow-2.7.1 pyyaml-6.0.1 querystring-parser-1.2.4 smmap-5.0.1 sqlalchemy-2.0.22 sqlparse-0.4.4 tabulate-0.9.0 websocket-client-1.6.4\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6921150-2961-4435-af73-3771c1542306",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "344ada11-9f70-4dfe-9cba-7b2f7b7b31bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d29bfe6b8614558aacfaab0b04a0648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BamboolibModuleWindow(children=(Window(children=(VBox(children=(VBox(children=(Button(description='Databricks:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bamboolib as bam\n",
    "\n",
    "bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6f10370-5ccf-469b-91f3-031753a2f94b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np\n",
    "emp_promotion_data = pd.read_csv(r'/dbfs/FileStore/tables/HR_Analytics.csv', sep=',', decimal='.', nrows=100000)\n",
    "# Step: Drop columns\n",
    "emp_promotion_data = emp_promotion_data.drop(columns=['employee_id', 'region'])\n",
    "\n",
    "# Step: Drop missing values in [All columns]\n",
    "emp_promotion_data = emp_promotion_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b997bf3c-c3cc-4f6c-9d70-2b6971e08e29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Checking the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1582a2a2-7e77-436c-a2f8-f6d9a4b3822a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48660, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_promotion_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c369982-598c-4442-bda6-d260ef6cc381",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now for doing some transformation( One hot encoding and Standard scaling) post train-test split and training our model along with tracking , we need to import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79965291-7690-4890-9510-03e12e5ba2a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "979159cc-3aa0-43d9-a8ff-3a23feeee4b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Splitting the data  into  train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f58f712-79a9-44b6-8219-3dd197e6f304",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((34062, 10), (14598, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = emp_promotion_data.drop('is_promoted', axis = 1)\n",
    "y = emp_promotion_data['is_promoted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd4925d1-c676-4bbf-a52f-845f8a2a34cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Saving processed train and test files for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c408e69c-aa4c-49a6-86aa-e15223776776",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('/dbfs/FileStore/tables/processed_x_train.csv', index = False)\n",
    "X_test.to_csv('/dbfs/FileStore/tables/processed_x_test.csv', index = False)\n",
    "y_train.to_csv('/dbfs/FileStore/tables/processed_y_train.csv', index = False)\n",
    "y_test.to_csv('/dbfs/FileStore/tables/processed_y_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94371f69-8157-4714-8b9b-58b6c2296247",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Categorical features are listed and One hot encoder is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd6d36de-6376-4ecd-ac1d-70c07a3e5ecb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = ['department', 'recruitment_channel', 'education', 'gender']\n",
    "\n",
    "categorical_transformer = OneHotEncoder(drop = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d67288aa-2a96-45fb-a1ad-73925c948993",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "ColumnTransformer : This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. Here We are using Column Transformer to one hot encode categorical features defined above and Standard scale remaining numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37fe48e2-023b-44b7-a852-5a4331e6b12a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer(remainder=StandardScaler(),\n                  transformers=[('cat', OneHotEncoder(drop='first'),\n                                 ['department', 'recruitment_channel',\n                                  'education', 'gender'])])\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [('cat', categorical_transformer, categorical_features)], \n",
    "    remainder = StandardScaler() \n",
    ")\n",
    "\n",
    "print(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7def32bb-639e-44a3-a18f-69efdbe310b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We are autologging parameters and metrics using mlflow.sklearn.autolog.\n",
    "Pipeline is defined with preprocessing and model building steps. We are using Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82f022d7-3437-4491-a6eb-2f43128d5fb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run_id: 271bbf331ceb4b39a8c89103f15ec7fd\n"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run() as run1:\n",
    "    \n",
    "    dtc = DecisionTreeClassifier()\n",
    "    pipeline = Pipeline( steps = [('preprocessor', preprocessor), ('classifier', dtc)])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    predictions =  pipeline.predict(X_test)\n",
    "    predictions_proba = pipeline.predict_proba(X_test)\n",
    "    \n",
    "    test_accuracy_score = accuracy_score(y_test, predictions)\n",
    "    test_precision_score = precision_score(y_test, predictions)\n",
    "    test_recall_score = recall_score(y_test, predictions)\n",
    "    test_f1_score = f1_score(y_test, predictions)\n",
    "    auc_score = roc_auc_score(y_test,  predictions_proba[:,1])\n",
    "    \n",
    "    mlflow.log_metric('test_accuracy', test_accuracy_score)\n",
    "    mlflow.log_metric('test_precision', test_precision_score)\n",
    "    mlflow.log_metric('test_recall_score', test_recall_score)\n",
    "    mlflow.log_metric('test_f1', test_f1_score)\n",
    "    mlflow.log_metric('auc_roc', auc_score)\n",
    "    \n",
    "    run1 = mlflow.active_run()\n",
    "    \n",
    "    print('Active run_id: {}'.format(run1.info.run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5546a91a-1f93-4648-b989-aab57a926bf8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Tuning manually some parameters and running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8007f3d8-7377-4637-bd2f-3742c5592fec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run_id: 0a80ba791fb9452cbc04e1ffa59b6065\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run2:\n",
    "\n",
    "    criterion = 'entropy'\n",
    "    max_depth = 2\n",
    "    min_samples_split = 5\n",
    "    min_samples_leaf = 3\n",
    "    \n",
    "    dtc = DecisionTreeClassifier(criterion = criterion, max_depth = max_depth,\n",
    "                                 min_samples_split = min_samples_split, \n",
    "                                 min_samples_leaf = min_samples_leaf)\n",
    "                                   \n",
    "    pipeline_tuned = Pipeline(steps = [('preprocessor', preprocessor), ('classifier', dtc)])\n",
    "    pipeline_tuned.fit(X_train, y_train)\n",
    "\n",
    "    predictions = pipeline_tuned.predict(X_test)\n",
    "    predictions_proba = pipeline_tuned.predict_proba(X_test)\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, predictions)\n",
    "    test_precision_score = precision_score(y_test, predictions)\n",
    "    test_recall_score = recall_score(y_test, predictions)\n",
    "    test_f1_score = f1_score(y_test, predictions)\n",
    "    auc_score = roc_auc_score(y_test,  predictions_proba[:, 1])\n",
    "    \n",
    "    mlflow.log_metric('test_accuracy', test_accuracy_score)\n",
    "    mlflow.log_metric('test_precision', test_precision_score)\n",
    "    mlflow.log_metric('test_recall_score', test_recall_score)\n",
    "    mlflow.log_metric('test_f1', test_f1_score)\n",
    "    mlflow.log_metric('auc_roc', auc_score)\n",
    "    \n",
    "    run2 = mlflow.active_run()\n",
    "    print('Active run_id: {}'.format(run2.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "049b2af8-5512-44ab-ac44-37ddb2059542",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'employee_promotion_prediction'.\n2023/10/15 12:38:06 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: employee_promotion_prediction, version 1\nCreated version '1' of model 'employee_promotion_prediction'.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'employee_promotion_prediction'\n",
    "\n",
    "model_version = mlflow.register_model(f'runs:/{run1.info.run_id}/model', model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcfa713a-d4ed-430b-a8cb-9714a7d3d71e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now for making predictions using the registered model we need to do model transistion to Production stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8e1b3a0-ac45-4e1b-bc26-af0657ac9273",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1697373486003, current_stage='Production', description='', last_updated_timestamp=1697373505992, name='employee_promotion_prediction', run_id='271bbf331ceb4b39a8c89103f15ec7fd', run_link='', source='dbfs:/databricks/mlflow-tracking/2763935754512599/271bbf331ceb4b39a8c89103f15ec7fd/artifacts/model', status='READY', status_message='', tags={}, user_id='521721293902460', version='1'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    " \n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "  name = model_name,\n",
    "  version = model_version.version,\n",
    "  stage = 'Production',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43f227ed-b613-4a3b-936b-5c0ea85ca446",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DATABRICKS_TOKEN'] = 'dapi8a1af64ed77bb948209bfab94e6764a1-3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0adf1ebf-e781-4f4b-87b2-783d3c4cf08d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Code updated for MLflow 2.0 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f742c15f-d480-4031-934c-3b2c5ab26800",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_tf_serving_json(data):\n",
    "  return {'inputs': {name: data[name].tolist() for name in data.keys()}}\n",
    "\n",
    "def score_model(dataset):\n",
    "  url = 'https://adb-1858010364734723.3.azuredatabricks.net/model/employee_promotion_prediction/1/invocations'\n",
    "  headers = {'Authorization': f'Bearer {os.environ.get(\"DATABRICKS_TOKEN\")}', 'Content-Type': 'application/json'}\n",
    "  ds_dict = create_tf_serving_json(dataset)\n",
    "  data_json = json.dumps(ds_dict, allow_nan=True)\n",
    "  print(data_json)  \n",
    "  response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "  if response.status_code != 200:\n",
    "    raise Exception(f'Request failed with status {response.status_code}, {response.text}')\n",
    "  return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74f0c991-f2a2-43f0-9840-68cf9c5308da",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Model serving is designed for low-latency predictions on smaller batches of data\n",
    "Comparing  the results from the deployed model and the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4979b9dc-2d47-452b-a9f0-07bb0921ec17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inputs\": {\"department\": [\"Operations\"], \"education\": [\"Master's & above\"], \"gender\": [\"m\"], \"recruitment_channel\": [\"other\"], \"no_of_trainings\": [1], \"age\": [46], \"previous_year_rating\": [4.0], \"length_of_service\": [16], \"awards_won?\": [0], \"avg_training_score\": [62]}}\n"
     ]
    }
   ],
   "source": [
    "num_predictions = 1\n",
    "\n",
    "served_predictions = score_model(X_test[:num_predictions])\n",
    "model_evaluations = pipeline.predict(X_test[:num_predictions])\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "  'Model Prediction': model_evaluations,\n",
    "  'Served Model Prediction': served_predictions['predictions'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a497f77e-f15f-4388-a6a8-4d165c3c22d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6d1df73864435790aba08154ff44f6"
      },
      "text/plain": [
       "    Model Prediction  Served Model Prediction\n",
       "20                 0                        0\n",
       "1                  0                        0\n",
       "4                  1                        1\n",
       "14                 0                        0\n",
       "6                  0                        0\n",
       "23                 0                        0\n",
       "18                 0                        0\n",
       "9                  1                        1\n",
       "5                  0                        0\n",
       "22                 0                        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d6831df-4275-4a3b-81f0-3424d445f4a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "On the same  serving page -> Click on \"browser\" and paste the below format for input example and get the prediction whether the case will be promoted or not according to the model(Response-0 in this case)\n",
    "This is not to use in notebook\n",
    "\n",
    "[ { \n",
    "  \"department\" : \"Sales & Marketing\", \n",
    "  \"education\" : \"Master's & above\", \n",
    "  \"gender\" : \"f\", \n",
    "  \"recruitment_channel\" : \"sourcing\", \n",
    "  \"no_of_trainings\" :1, \n",
    "  \"age\" : \"35\", \n",
    "  \"previous_year_rating\" : 5.0, \n",
    "  \"length_of_service\" : 8, \n",
    "  \"awards_won?\" : 0, \n",
    "  \"avg_training_score\" : 49 \n",
    "} ]\n",
    "\n",
    "#### New format for MLflow 2.0\n",
    "\n",
    "{\"inputs\": \n",
    "{ \n",
    "  \"department\" : [\"Sales & Marketing\"], \n",
    "  \"education\" : [\"Master's & above\"], \n",
    "  \"gender\" : [\"f\"], \n",
    "  \"recruitment_channel\" : [\"sourcing\"], \n",
    "  \"no_of_trainings\" :[1], \n",
    "  \"age\" : [\"35\"], \n",
    "  \"previous_year_rating\" : [5.0], \n",
    "  \"length_of_service\" : [8], \n",
    "  \"awards_won?\" : [0], \n",
    "  \"avg_training_score\" : [49] \n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64e10e58-1c2a-4136-aaab-48c76e71986f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For below case, Response is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "999c564e-c35f-428e-8875-4cf751234986",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "[\n",
    "  {\n",
    "\"department\" : \"Sales & Marketing\",\n",
    "\"education\" : \"Master's & above\",\n",
    "\"gender\" : \"m\",\n",
    "\"recruitment_channel\" : \"other\",\n",
    "\"no_of_trainings\" :1,\n",
    "\"age\" : \"34\",\n",
    "\"previous_year_rating\" : 3.0,\n",
    "\"length_of_service\" : 7,\n",
    "\"awards_won?\" : 0,\n",
    "\"avg_training_score\" : 60 \n",
    "  }\n",
    "]\n",
    "\n",
    "#### New format for MLflow 2.0\n",
    "\n",
    "{\"inputs\": { \"department\" : [\"Sales & Marketing\"], \"education\" : [\"Master's & above\"], \"gender\" : [\"m\"], \"recruitment_channel\" : [\"other\"], \"no_of_trainings\" :[1], \"age\" : [\"34\"], \"previous_year_rating\" : [3.0], \"length_of_service\" : [7], \"awards_won?\" : [0], \"avg_training_score\" : [60] } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "933abe69-afcf-4350-baad-d72bf17857f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5f570e0-6c73-4c26-8871-5e3836c1da80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ClassificationUsingScikitLearnPipeline",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
